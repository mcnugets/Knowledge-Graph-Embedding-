{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a6c5ab",
   "metadata": {},
   "source": [
    "## Running OWL2Vec*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2658935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Access the ontology ...\n",
      "INFO: There are 1945 triples in the ontology\n",
      "INFO: Calculate the ontology projection ...\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.09635281562805176 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.020321369171142578 seconds \n",
      "INFO: \tExtracting class membership triples.\n",
      "INFO: \t\tTime extracting class membership: 0.2740170955657959 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.007066488265991211 seconds \n",
      "INFO: \tExtracting triples associated to hasBase\n",
      "INFO: \t\tTime extracting triples for property: 0.11343240737915039 seconds \n",
      "INFO: \tExtracting triples associated to hasIngredient\n",
      "INFO: \t\tTime extracting triples for property: 0.11119937896728516 seconds \n",
      "INFO: \tExtracting triples associated to isBaseOf\n",
      "INFO: \t\tTime extracting triples for property: 0.11312150955200195 seconds \n",
      "INFO: \tExtracting triples associated to hasCountryOfOrigin\n",
      "INFO: \t\tTime extracting triples for property: 0.1146841049194336 seconds \n",
      "INFO: \tExtracting triples associated to isIngredientOf\n",
      "INFO: \t\tTime extracting triples for property: 0.11023473739624023 seconds \n",
      "INFO: \tExtracting triples associated to hasSpiciness\n",
      "INFO: \t\tTime extracting triples for property: 0.13178467750549316 seconds \n",
      "INFO: \tExtracting triples associated to hasTopping\n",
      "INFO: \t\tTime extracting triples for property: 0.19117450714111328 seconds \n",
      "INFO: \tExtracting triples associated to isToppingOf\n",
      "INFO: \t\tTime extracting triples for property: 0.11382341384887695 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.0004398822784423828 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 3.750458002090454 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.5765566825866699 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n",
      "INFO: Extract classes and individuals ...\n",
      "INFO: Extract axioms ...\n",
      "INFO: Extract annotations ...\n",
      "INFO: Generate URI document ...\n",
      "INFO: Extracted 3350 walks for 104 seed entities\n",
      "INFO: Extracted 279 axiom sentences\n",
      "INFO: Generate literal document ...\n",
      "INFO: Extracted 34 annotation sentences\n",
      "INFO: Generate mixture document ...\n",
      "INFO: URI_Doc: 3629, Lit_Doc: 12069, Mix_Doc: 3629\n",
      "INFO: Time for document construction: 7.422607421875 seconds\n",
      "INFO: Train the language model ...\n",
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: PROGRESS: at sentence #10000, processed 58073 words, keeping 637 word types\n",
      "INFO: collected 784 word types from a corpus of 112767 raw words and 19327 sentences\n",
      "INFO: Creating a fresh vocabulary\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 784 unique words (100.0%% of original 784, drops 0)', 'datetime': '2022-04-03T18:28:06.924902', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 112767 word corpus (100.0%% of original 112767, drops 0)', 'datetime': '2022-04-03T18:28:06.926732', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: deleting the raw counts dictionary of 784 items\n",
      "INFO: sample=0.001 downsamples 58 most-common words\n",
      "INFO: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 52936.755037884875 word corpus (46.9%% of prior 112767)', 'datetime': '2022-04-03T18:28:06.932713', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: estimated required memory for 784 words and 100 dimensions: 1019200 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-04-03T18:28:06.943239', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'build_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 784 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=25 window=5 shrink_windows=True', 'datetime': '2022-04-03T18:28:06.944819', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 1 : training on 112767 raw words (52916 effective words) took 0.2s, 290548 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 2 : training on 112767 raw words (52914 effective words) took 0.2s, 322542 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 3 : training on 112767 raw words (52978 effective words) took 0.2s, 317899 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 4 : training on 112767 raw words (53011 effective words) took 0.2s, 296570 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 5 : training on 112767 raw words (52913 effective words) took 0.2s, 332908 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 6 : training on 112767 raw words (53015 effective words) took 0.2s, 308305 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 7 : training on 112767 raw words (52871 effective words) took 0.2s, 337539 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 8 : training on 112767 raw words (52773 effective words) took 0.2s, 303029 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 9 : training on 112767 raw words (53070 effective words) took 0.2s, 330479 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 10 : training on 112767 raw words (52951 effective words) took 0.2s, 343966 effective words/s\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training on 1127670 raw words (529412 effective words) took 1.7s, 302683 effective words/s', 'datetime': '2022-04-03T18:28:08.695156', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "INFO: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=784, vector_size=100, alpha=0.025)', 'datetime': '2022-04-03T18:28:08.695571', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "INFO: Time for learning the language model: 1.8026082515716553 seconds\n",
      "INFO: Word2Vec lifecycle event {'fname_or_handle': './cache/output/ontology.embeddings', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-04-03T18:28:08.701915', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "INFO: not storing attribute cum_table\n",
      "INFO: saved ./cache/output/ontology.embeddings\n",
      "INFO: storing 784x100 projection weights into ./cache/output/ontology.embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "from owl2vec_star import owl2vec_star\n",
    "\n",
    "\n",
    "#Parameters:\n",
    "# ontology_file\n",
    "# config_file\n",
    "# uri_doc\n",
    "# lit_doc\n",
    "# mix_doc\n",
    "gensim_model = owl2vec_star.extract_owl2vec_model(\"./case_studies/pizza/pizza.owl\", \"./default.cfg\", True, True, True)\n",
    "\n",
    "output_folder=\"./cache/output/\"\n",
    "\n",
    "#Gensim format\n",
    "gensim_model.save(output_folder+\"ontology.embeddings\")\n",
    "    #Txt format\n",
    "gensim_model.wv.save_word2vec_format(output_folder+\"ontology.embeddings.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a78df2",
   "metadata": {},
   "source": [
    "## Loading embeddings and getting similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdbcf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: loading KeyedVectors object from ./cache/output/ontology.embeddings\n",
      "INFO: loading wv recursively from ./cache/output/ontology.embeddings.wv.* with mmap=r\n",
      "INFO: setting ignored attribute cum_table to None\n",
      "INFO: Word2Vec lifecycle event {'fname': './cache/output/ontology.embeddings', 'datetime': '2022-04-03T18:28:17.538248', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'pizza'\n",
      "[ 0.11139922  0.03455254  0.15158105  0.6114894   0.20663601  0.53395736\n",
      " -0.09197029 -0.07173101  0.1752342  -0.65811926 -0.01860704  0.04644626\n",
      "  0.1417845  -0.03679806 -0.2661091   0.10978213  0.07950623 -0.7604301\n",
      " -0.10540137  0.27380154 -0.13372116 -0.02536337  0.05202136  0.41834542\n",
      "  0.3444666  -0.8851259  -0.13122185  0.2619441  -0.3702318  -0.00967073\n",
      " -0.26868883 -0.3947839  -0.44641    -0.4967901   0.0247598  -0.84458625\n",
      "  0.31117314 -0.01431737 -0.49218348  0.21242924  0.4751569  -0.3522823\n",
      "  0.06369893 -0.2756807   0.17864463 -0.27719304 -0.01182104  0.6601959\n",
      "  0.28241694 -0.11273695  0.4635236   0.03246771  0.18720752 -0.3095463\n",
      "  0.3554481  -0.01066254 -0.13979104 -0.09713667 -0.08568931  0.11690582\n",
      "  0.8871984  -0.3686109  -0.08434672  0.43349743 -0.06122519  0.2322311\n",
      "  0.18166268 -0.1607971  -0.39743292 -0.08293543  0.41001576 -0.09654567\n",
      " -0.17758472 -0.1504669   0.30046737 -0.02178798  0.5750125  -0.0110304\n",
      " -0.07889778 -0.36994055  0.41333762  0.3452365  -0.6243669   0.28717917\n",
      " -0.15630476 -0.01276457 -0.3755662  -0.27718842  0.33268133  0.13209507\n",
      "  0.42390737  0.69995517  0.3696406   0.13451871 -0.02866815 -0.31370863\n",
      " -0.2556705  -0.30294833 -0.06758998 -0.10825583]\n",
      "0.48374757\n",
      "0.80984086\n",
      "[('rosa pizza', 0.7967075109481812), ('parmese pizza', 0.7939520478248596), ('unclosedpizza', 0.784817099571228), ('margherita pizza', 0.7771976590156555), ('mushroom pizza', 0.7761094570159912), ('veneziana pizza', 0.7617127299308777), ('sundried tomato', 0.7604901194572449), ('soho pizza', 0.757476270198822), ('american pizza', 0.749670147895813), ('caprina pizza', 0.7450791001319885)]\n",
      "[('unclosedpizza', 0.9122495055198669), ('unclosed', 0.9057228565216064), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 0.9049196243286133), ('rosa pizza', 0.8869567513465881), ('rosa', 0.8840981721878052), ('margherita pizza', 0.8824605941772461), ('sundried tomato', 0.8810267448425293), ('veneziana pizza', 0.8807700872421265), ('mushroom pizza', 0.8781152367591858), ('caprina pizza', 0.8700227737426758)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Embedding vectors generated above\n",
    "model = KeyedVectors.load(\"./cache/output/ontology.embeddings\", mmap='r')\n",
    "wv = model.wv\n",
    "\n",
    "vector = wv['pizza']  # Get numpy vector of a word\n",
    "print(\"Vector for 'pizza'\")\n",
    "print(vector)\n",
    "\n",
    "#cosine similarity\n",
    "similarity = wv.similarity('pizza', 'http://www.co-ode.org/ontologies/pizza/pizza.owl#Pizza')\n",
    "print(similarity)\n",
    "\n",
    "similarity = wv.similarity('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 'margherita')\n",
    "print(similarity)\n",
    "\n",
    "\n",
    "#Most similar cosine similarity\n",
    "result = wv.most_similar(positive=['margherita', 'pizza'])\n",
    "print(result)\n",
    "\n",
    "#Most similar entities: cosmul\n",
    "result = wv.most_similar_cosmul(positive=['margherita'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdbe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
